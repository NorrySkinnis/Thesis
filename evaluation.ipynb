{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5e8eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import vonmises\n",
    "from scipy.stats import norm, uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f2e53",
   "metadata": {},
   "source": [
    "Alternated version of the network class to enable automated plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6b9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, width, depth):\n",
    "        \n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        if depth == 4:\n",
    "            \n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(7, width),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(width, width),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(width, width),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(width, width),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(width, 1),\n",
    "                nn.Sigmoid())\n",
    "            \n",
    "        elif depth == 3:\n",
    "            \n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(7, width),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(width, width),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(width, width),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(width, 1),\n",
    "                nn.Sigmoid())\n",
    "        else: \n",
    "            \n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(7, width),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(width, width),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(width, 1),\n",
    "                nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        output = self.linear_relu_stack(x)\n",
    "        \n",
    "        return output\n",
    "\n",
    "def get_model(width, depth):\n",
    "\n",
    "    model = NeuralNetwork(width, depth).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.L1Loss()\n",
    "\n",
    "    return model, optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df7cba",
   "metadata": {},
   "source": [
    "Evaluation of the networks: \n",
    "\n",
    "- Training errors \n",
    "- Interpolation performance\n",
    "- Extended ranges errors \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca36192",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(f'data/training/in_{5}_{20}_{20}.npz')['arr_0']\n",
    "y_train = np.load(f'data/training/ts_{5}_{20}_{20}.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training error\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,7.5)\n",
    "plt.rcParams['axes.spines.right'] = True\n",
    "plt.rcParams['axes.spines.top'] = True\n",
    "\n",
    "\n",
    "mode = 'training'\n",
    "targets = y_train \n",
    "inputs = X_train\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "networks = [[100, 75, 50, 25], [71, 54, 36, 18], [59, 44, 30, 15]]\n",
    "batch_sizes = [125, 250, 500]\n",
    "folds = 4\n",
    "\n",
    "n = len(targets)\n",
    "\n",
    "all_errors = []\n",
    "all_models = []\n",
    "all_b_s = [] \n",
    "\n",
    "for b_s in tqdm(batch_sizes):\n",
    "        \n",
    "    for d, n_w in enumerate(networks):\n",
    "        \n",
    "        errors = []\n",
    "        \n",
    "        for w in n_w:\n",
    "        \n",
    "            tag = 'relu'+ (d+2) * f'_{w}'\n",
    "            e = 0 \n",
    "            \n",
    "            for f in range(folds):\n",
    "                \n",
    "                model, optimizer, loss_fn = get_model(w, d+2)\n",
    "                model.load_state_dict(torch.load(f'models/{tag}/{tag}_batch_size_{b_s}_fold_{f+1}.pt', map_location=torch.device('cpu')))\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    \n",
    "                    y_pred = model(torch.Tensor(inputs)).detach().numpy().ravel()\n",
    "                \n",
    "                e += np.sum(np.abs(y_pred - targets))\n",
    "            \n",
    "            errors.append(e / (n * folds))\n",
    "        all_errors.append((n_w , errors))\n",
    "        \n",
    "        x = [100, 75, 50, 25]\n",
    "        plt.scatter(x, errors, label=f'depth={d+2}', marker='o')\n",
    "        \n",
    "        if d > 0:\n",
    "            for i, txt in enumerate(n_w):\n",
    "                plt.annotate(txt, (x[i], errors[i]), fontsize=15)\n",
    "    \n",
    "    plt.xticks([100, 75, 50, 25])\n",
    "    plt.yticks(np.linspace(0.004, 0.02, 5))\n",
    "    plt.tick_params(labelsize=20, pad=15)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.title(f'Batch Size = {b_s}', fontsize=20)\n",
    "    plt.ylabel('\\n L1-Loss', fontsize=20, linespacing=3.5)\n",
    "    if b_s==500:\n",
    "        plt.xlabel('Hidden Layer Size of Reference Networks (blue)', fontsize=20)\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.savefig(f'plots/{mode}_summary_{b_s}.png', bbox_inches='tight') \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation error\n",
    "\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "X_r = np.load(f'data/training/in_5_20_20.npz')['arr_0']\n",
    "y_r = np.load(f'data/training/ts_5_20_20.npz')['arr_0']\n",
    "\n",
    "X_data.append(X_r)\n",
    "y_data.append(y_r)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    X_r = np.load(f'data/testing/in_full_model_left_{i+1}.npz')['arr_0']\n",
    "    y_r = np.load(f'data/testing/ts_full_model_left_{i+1}.npz')['arr_0']\n",
    "    \n",
    "    X_data.append(X_r)\n",
    "    y_data.append(y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a108d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,7.5)\n",
    "plt.rcParams['axes.spines.right'] = True\n",
    "plt.rcParams['axes.spines.top'] = True\n",
    "\n",
    "component = 'full_model' # change here\n",
    "networks = [[100, 75, 50, 25], [71, 54, 36, 18], [59, 44, 30, 15]]\n",
    "batch_sizes = [125, 250, 500]\n",
    "folds = 4\n",
    "\n",
    "for b_s in tqdm(batch_sizes):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(70,20),subplot_kw=dict(projection='3d'))\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(r'$\\beta_{H_s}$, $\\kappa_v$, $\\kappa_h$, $\\tau$, $\\sigma_{H_p}$, Training Batch Size = ' + f'{b_s}',\n",
    "                 y = 1, fontsize=60) # change here\n",
    "    \n",
    "    for d, n_w in enumerate(networks):\n",
    "        \n",
    "        x_values = []\n",
    "        y_values = []\n",
    "        errors = []\n",
    "        \n",
    "        for w in n_w:\n",
    "        \n",
    "            tag = 'relu'+ (d+2) * f'_{w}'\n",
    "            \n",
    "            for i in range(0, len(X_data)):\n",
    "                \n",
    "                e = 0 \n",
    "\n",
    "                for f in range(folds):\n",
    "                \n",
    "                    model, optimizer, loss_fn = get_model(w, d+2)\n",
    "                    model.load_state_dict(torch.load(f'models/{tag}/{tag}_batch_size_{b_s}_fold_{f+1}.pt', map_location=torch.device('cpu')))\n",
    "                \n",
    "                    with torch.no_grad():\n",
    "                    \n",
    "                        y_pred_r = model(torch.Tensor(X_data[i])).detach().numpy().ravel()\n",
    "\n",
    "                    \n",
    "                    e += np.sum(np.abs(y_pred_r - y_data[i])) / len(y_data[i]) \n",
    "                    \n",
    "                errors.append(e / folds)\n",
    "                x_values.append(w)\n",
    "                y_values.append(1-0.2*i)\n",
    "\n",
    "                \n",
    "        ax[d].plot_trisurf(y_values, x_values, errors, vmin=0.004, vmax=0.024, cmap='summer', edgecolor='none')\n",
    "        ax[d].view_init(20, 70)\n",
    "        ax[d].tick_params(labelsize=40, pad=40)\n",
    "        ax[d].set_xlabel('\\n Training-Testing Data Similarity', fontsize=50, linespacing=5.5)        \n",
    "        ax[d].set_xticks(y_values)\n",
    "        ax[d].set_ylabel('\\n Hidden Layer Size', fontsize=50, linespacing=5.5)\n",
    "        ax[d].set_yticks(n_w)\n",
    "        ax[d].set_zticks(np.linspace(0.004, 0.024, 6))\n",
    "        ax[d].set_zlabel('\\n L1-Loss', fontsize=50, linespacing=7.5)\n",
    "        ax[d].set_title(f'Depth = {d+2}', y=1, fontsize=50)\n",
    "        \n",
    "    fig.savefig(f'plots/training_testing_convergence_{component}_left_{b_s}.png')\n",
    "    plt.close(fig)\n",
    "    \n",
    "print('Plots generated and saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c63fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(f'data/testing/in_tau_distribution.npz')['arr_0']\n",
    "y = np.load(f'data/testing/ts_tau_distribution.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0b2ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended ranges error\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,7.5)\n",
    "plt.rcParams['axes.spines.right'] = True\n",
    "plt.rcParams['axes.spines.top'] = True\n",
    "\n",
    "component = 'tau' # change here\n",
    "networks = [[100, 75, 50, 25], [71, 54, 36, 18], [59, 44, 30, 15]]\n",
    "batch_sizes = [125, 250, 500]\n",
    "folds = 4\n",
    "\n",
    "n = len(X)\n",
    "x_values = np.unique(X[:,3]) # change here\n",
    "\n",
    "for b_s in tqdm(batch_sizes):\n",
    "\n",
    "    for d, n_w in enumerate(networks):\n",
    "        \n",
    "        for w in n_w:\n",
    "        \n",
    "            tag = 'relu'+ (d+2) * f'_{w}'\n",
    "                  \n",
    "            errors = np.zeros(8)\n",
    "                \n",
    "            for f in range(folds):\n",
    "                \n",
    "                model, optimizer, loss_fn = get_model(w, d+2)\n",
    "                model.load_state_dict(torch.load(f'models/{tag}/{tag}_batch_size_{b_s}_fold_{f+1}.pt', map_location=torch.device('cpu')))\n",
    "                    \n",
    "                    \n",
    "                for i in range(0, n, 102400):\n",
    "                        \n",
    "                    with torch.no_grad():\n",
    "                    \n",
    "                        y_pred = model(torch.Tensor(X)).detach().numpy().ravel()\n",
    "                        \n",
    "                    errors[int(i / 102400)] += np.sum(np.abs(y[i:i + 102400] - y_pred[i:i + 102400])) / 102400\n",
    "                    \n",
    "            errors = errors / folds\n",
    "                \n",
    "            \n",
    "            plt.scatter(x_values, errors, label=f'size={w}', marker='_', s=40)\n",
    "\n",
    "        plt.axvspan(0.79, 1, facecolor='grey', alpha=0.05)\n",
    "        plt.annotate('Training Range', xy=(0.643 , 0.9), xycoords='axes fraction', fontsize=15)\n",
    "        plt.tick_params(labelsize=20, pad=15)\n",
    "        plt.xlabel(r'$\\tau}$', fontsize=20) \n",
    "        plt.ylabel('L1-Loss', fontsize=20)\n",
    "        plt.yticks(np.linspace(0, 0.15, 6))\n",
    "        plt.title(r'Error Distribution of $\\tau$ for'+ f' Depth-{d+2} Networks, Batch Size = {b_s}', fontsize=20) \n",
    "        plt.legend(loc='center', bbox_to_anchor=(0.72, 0.72), fontsize=15) \n",
    "        plt.savefig(f'plots/error_distribution_{component}_depth_{d+2}_{b_s}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c905a",
   "metadata": {},
   "source": [
    "Evaluation of adaptive stimulus selection:\n",
    "- Stimuli absolute frequencies\n",
    "- Stimulus selection\n",
    "- Mean marginal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d186f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = 5\n",
    "n_trials = 500\n",
    "true_params = [0.02, 0.0384, 86.2428, 1.4506, 0.8, 0.1134]  # lambda, beta_hs, kv, kh, tau, sigma_hp\n",
    "nr = 4\n",
    "\n",
    "frames = np.load(f'data/adaptive_stimulus_selection/disc_{disc}_frames_run_{nr}.npz')['arr_0']\n",
    "rods = np.load(f'data/adaptive_stimulus_selection/disc_{disc}_rods_run_{nr}.npz')['arr_0']\n",
    "avg_estimates = np.load(f'data/adaptive_stimulus_selection/disc_{disc}_avg_estimates_run_{nr}.npz')['arr_0']\n",
    "map_estimates = np.load(f'data/adaptive_stimulus_selection/disc_{disc}_map_estimates_run_{nr}.npz')['arr_0']\n",
    "priors =  np.load(f'data/adaptive_stimulus_selection/disc_{disc}_priors_run_{nr}.npz')['arr_0']\n",
    "param_values =  np.load(f'data/adaptive_stimulus_selection/disc_{disc}_params.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfefe762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stimuli absolute frequencies\n",
    "\n",
    "x_bins = np.linspace(-37.5,27.5,14)\n",
    "y_bins= np.linspace(-7.5, 4.5, 13)\n",
    "plt.hist2d(frames, rods, cmap='summer', bins=[x_bins, y_bins])\n",
    "plt.xticks(np.linspace(-35, 25, 7))\n",
    "plt.xlabel('Frame Orientations 째', fontsize=15)\n",
    "plt.ylabel('Rod Orientations 째', fontsize=15)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.colorbar()\n",
    "plt.savefig('plots/stimulus_selection_frequency.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57088c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stimulus Selection\n",
    "\n",
    "x = np.linspace(1,500,500)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20,6))\n",
    "ax[0].tick_params(labelsize=15)\n",
    "ax[0].scatter(x, rods, s=10, marker='_', color='gray')\n",
    "ax[0].set_xticks([1, 100, 200, 300, 400, 500])\n",
    "ax[0].set_yticks([-7, -5, -3, -1, 1, 3, 5, 7])\n",
    "ax[0].set_title('Rods', fontsize=20)\n",
    "ax[0].set_ylabel('Rod Orientation 째', fontsize=20)\n",
    "ax[0].set_xlabel('\\n Trial Number', fontsize=20, linespacing=0.1)\n",
    "\n",
    "\n",
    "ax[1].tick_params(labelsize=15)\n",
    "ax[1].scatter(x, frames, s=10, marker='_', color='green')\n",
    "ax[1].set_xticks([1, 100, 200, 300, 400, 500])\n",
    "ax[1].set_yticks(np.linspace(-40,40,9))\n",
    "ax[1].set_title('Frames', fontsize=20)\n",
    "ax[1].set_ylabel('Frame Orientation 째', fontsize=20)\n",
    "ax[1].set_xlabel('\\n Trial Number', fontsize=20, linespacing=0.1)\n",
    "\n",
    "fig.savefig(f'plots/stimulus_selection.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709651c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean marginal distributions\n",
    "\n",
    "marginal_lambda_means = np.zeros((n_trials, disc))\n",
    "marginal_beta_means = np.zeros((n_trials, disc))\n",
    "marginal_kv_means = np.zeros((n_trials, disc))\n",
    "marginal_kh_means = np.zeros((n_trials, disc))\n",
    "marginal_tau_means = np.zeros((n_trials, disc))\n",
    "marginal_sigma_means = np.zeros((n_trials, disc))\n",
    "\n",
    "for nr in tqdm(range(1,11)):\n",
    "    \n",
    "    priors =  np.load(f'data/adaptive_stimulus_selection/disc_{disc}_priors_run_{nr}.npz')['arr_0']\n",
    "    \n",
    "    marginal_lambda = np.zeros((n_trials, disc))\n",
    "    marginal_sigma = np.zeros((n_trials, disc))\n",
    "    marginal_tau = np.zeros((n_trials, disc))\n",
    "    marginal_kv = np.zeros((n_trials, disc))\n",
    "    marginal_kh = np.zeros((n_trials, disc))\n",
    "    marginal_beta = np.zeros((n_trials, disc))\n",
    "    \n",
    "    for t in range(n_trials):\n",
    "    \n",
    "        marginal_lambda[t:] = np.array([np.sum([priors[t][i + j * disc] for j in range(disc**5)]) for i in range(disc)])\n",
    "        marginal_sigma[t:] = np.array([np.sum([priors[t][j * disc + i * disc**2 : (j+1) * disc + i * disc**2] for i in range(int((disc**6 - disc**2) / disc**2) + 1)]) for j in range(disc)])\n",
    "        marginal_tau[t:] = np.array([np.sum([priors[t][j * disc**2 + i * disc**3 : (j+1) * disc**2 + i * disc**3] for i in range(int((disc**6 - disc**3) / disc**3) + 1)]) for j in range(disc)])\n",
    "        marginal_kh[t:] = np.array([np.sum([priors[t][j * disc**3 + i * disc**4 : (j+1) * disc**3 + i * disc**4] for i in range(int((disc**6 - disc**4) / disc**4) + 1)]) for j in range(disc)])\n",
    "        marginal_kv[t:] = np.array([np.sum([priors[t][j * disc**4 + i * disc**5 : (j+1) * disc**4 + i * disc**5] for i in range(int((disc**6 - disc**5) / disc**5) + 1)]) for j in range(disc)])\n",
    "        marginal_beta[t:] = np.array([np.sum([priors[t][j * disc**5 : (j+1) * disc**5]]) for j in range(disc)])\n",
    "    \n",
    "    marginal_lambda_means += marginal_lambda / 10\n",
    "    marginal_beta_means += marginal_beta / 10\n",
    "    marginal_kv_means += marginal_kv / 10\n",
    "    marginal_kh_means += marginal_kh / 10\n",
    "    marginal_tau_means += marginal_tau / 10\n",
    "    marginal_sigma_means += marginal_sigma / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e98f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance around mean marginal probabilities\n",
    "\n",
    "marginal_lambda_var = np.zeros((n_trials, disc))\n",
    "marginal_beta_var = np.zeros((n_trials, disc))\n",
    "marginal_kv_var = np.zeros((n_trials, disc))\n",
    "marginal_kh_var = np.zeros((n_trials, disc))\n",
    "marginal_tau_var = np.zeros((n_trials, disc))\n",
    "marginal_sigma_var = np.zeros((n_trials, disc))\n",
    "\n",
    "for nr in tqdm(range(1,11)):\n",
    "    \n",
    "    priors =  np.load(f'data/adaptive_stimulus_selection/disc_{disc}_priors_run_{nr}.npz')['arr_0']\n",
    "    \n",
    "    marginal_lambda = np.zeros((n_trials, disc))\n",
    "    marginal_sigma = np.zeros((n_trials, disc))\n",
    "    marginal_tau = np.zeros((n_trials, disc))\n",
    "    marginal_kv = np.zeros((n_trials, disc))\n",
    "    marginal_kh = np.zeros((n_trials, disc))\n",
    "    marginal_beta = np.zeros((n_trials, disc))\n",
    "    \n",
    "    for t in range(n_trials):\n",
    "    \n",
    "        marginal_lambda[t:] = np.array([np.sum([priors[t][i + j * disc] for j in range(disc**5)]) for i in range(disc)])\n",
    "        marginal_sigma[t:] = np.array([np.sum([priors[t][j * disc + i * disc**2 : (j+1) * disc + i * disc**2] for i in range(int((disc**6 - disc**2) / disc**2) + 1)]) for j in range(disc)])\n",
    "        marginal_tau[t:] = np.array([np.sum([priors[t][j * disc**2 + i * disc**3 : (j+1) * disc**2 + i * disc**3] for i in range(int((disc**6 - disc**3) / disc**3) + 1)]) for j in range(disc)])\n",
    "        marginal_kh[t:] = np.array([np.sum([priors[t][j * disc**3 + i * disc**4 : (j+1) * disc**3 + i * disc**4] for i in range(int((disc**6 - disc**4) / disc**4) + 1)]) for j in range(disc)])\n",
    "        marginal_kv[t:] = np.array([np.sum([priors[t][j * disc**4 + i * disc**5 : (j+1) * disc**4 + i * disc**5] for i in range(int((disc**6 - disc**5) / disc**5) + 1)]) for j in range(disc)])\n",
    "        marginal_beta[t:] = np.array([np.sum([priors[t][j * disc**5 : (j+1) * disc**5]]) for j in range(disc)])\n",
    "    \n",
    "    marginal_lambda_var += (marginal_lambda_means - marginal_lambda)**2 / 10\n",
    "    marginal_beta_var += (marginal_beta_means - marginal_beta)**2 / 10\n",
    "    marginal_kv_var += (marginal_kv_means - marginal_kv)**2 / 10 \n",
    "    marginal_kh_var += (marginal_kh_means - marginal_kh)**2 / 10\n",
    "    marginal_tau_var += (marginal_tau_means - marginal_tau)**2 / 10\n",
    "    marginal_sigma_var += (marginal_sigma_means - marginal_sigma)**2 / 10     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333eb2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.spines.right'] = True\n",
    "plt.rcParams['axes.spines.top'] = True\n",
    "\n",
    "betas = np.linspace(0.0366, 0.1257, disc)\n",
    "k_vs = np.linspace(50.6595, 133.6400, disc)\n",
    "k_hs = np.linspace(0.5274, 9.9156, disc)\n",
    "taus = np.linspace(0.79, 1, disc)\n",
    "sigmas = np.linspace(0.0942, 0.2862, disc)\n",
    "lambdas = np.linspace(0.001, 0.04, disc)\n",
    "\n",
    "\n",
    "plt.errorbar(lambdas, marginal_lambda_means[-1], yerr=marginal_lambda_var[-1], fmt='.', color='grey', ecolor='black', elinewidth=0.5, capsize=2);\n",
    "plt.vlines(true_params[0], 0, 0.3, color='lightgreen')\n",
    "plt.ylim(ymin=0, ymax=0.3)\n",
    "plt.xticks(lambdas)\n",
    "plt.yticks([0.05, 0.1, 0.15, 0.2, 0.25, 0.3])\n",
    "plt.title(r'$\\lambda$', fontsize=15)\n",
    "plt.ylabel(r'$P(\\lambda | D)$', fontsize=15)\n",
    "plt.savefig(f'plots/lambda_marginal.png')\n",
    "plt.close()\n",
    "\n",
    "plt.errorbar(betas, marginal_beta_means[-1], yerr=marginal_beta_var[-1], fmt='.', color='grey', ecolor='black', elinewidth=0.5, capsize=2);\n",
    "plt.vlines(true_params[1], -0.05, 1, color='lightgreen')\n",
    "plt.ylim(ymin=-0.05, ymax=1)\n",
    "plt.xticks(betas)\n",
    "plt.title(r'$\\beta_{H_s}$', fontsize=15)\n",
    "plt.ylabel(r'$P(\\beta_{H_s}| D)$', fontsize=15)\n",
    "plt.savefig(f'plots/beta_marginal.png')\n",
    "plt.close()\n",
    "\n",
    "plt.errorbar(k_vs, marginal_kv_means[-1], yerr=marginal_kv_var[-1], fmt='.', color='grey', ecolor='black', elinewidth=0.5, capsize=2);\n",
    "plt.vlines(true_params[2], 0, 1, color='lightgreen')\n",
    "plt.ylim(ymin=0, ymax=0.4)\n",
    "plt.yticks([0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "plt.xticks(k_vs)\n",
    "plt.title(r'$\\kappa_v$', fontsize=15)\n",
    "plt.ylabel(r'$P(\\kappa_v | D)$', fontsize=15)\n",
    "plt.savefig(f'plots/kv_marginal.png')\n",
    "plt.close()\n",
    "\n",
    "plt.errorbar(k_hs, marginal_kh_means[-1], yerr=marginal_kh_var[-1], fmt='.', color='grey', ecolor='black', elinewidth=0.5, capsize=2);\n",
    "plt.vlines(true_params[3], -0.05, 1, color='lightgreen')\n",
    "plt.ylim(ymin=-0.01, ymax=0.45)\n",
    "plt.xticks(k_hs)\n",
    "plt.title(r'$\\kappa_h$', fontsize=15)\n",
    "plt.ylabel(r'$P(\\kappa_h | D)$', fontsize=15)\n",
    "plt.savefig(f'plots/kh_marginal.png')\n",
    "plt.close()\n",
    "\n",
    "plt.errorbar(taus, marginal_tau_means[-1], yerr=marginal_tau_var[-1], fmt='.', color='grey', ecolor='black', elinewidth=0.5, capsize=2);\n",
    "plt.vlines(true_params[4], -0.05, 1, color='lightgreen')\n",
    "plt.ylim(ymin=0, ymax=0.25)\n",
    "plt.xticks(taus)\n",
    "plt.yticks([0.05, 0.1, 0.15, 0.2, 0.25])\n",
    "plt.title(r'$\\tau$', fontsize=15)\n",
    "plt.ylabel(r'$P(\\tau | D)$', fontsize=15)\n",
    "plt.savefig(f'plots/tau_marginal.png')\n",
    "plt.close()\n",
    "\n",
    "plt.errorbar(sigmas, marginal_sigma_means[-1], yerr=marginal_sigma_var[-1], fmt='.', color='grey', ecolor='black', elinewidth=0.5, capsize=2);\n",
    "plt.vlines(true_params[5], -0.05, 1, color='lightgreen')\n",
    "plt.ylim(ymin=0, ymax=0.25)\n",
    "plt.xticks(sigmas)\n",
    "plt.yticks([0.05, 0.1, 0.15, 0.2, 0.25])\n",
    "plt.title(r'$\\sigma_{H_p}$', fontsize=15)\n",
    "plt.ylabel(r'$P(\\sigma_{H_p} | D)$', fontsize=15)\n",
    "plt.savefig(f'plots/sigma_marginal.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
